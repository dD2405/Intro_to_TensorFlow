{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7 Saving and Loading Models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMc0v1xfK7ovD/6jIR7PHSC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dD2405/Intro_to_TensorFlow/blob/master/7_Saving_and_Loading_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV7VnVvhqLXn",
        "colab_type": "text"
      },
      "source": [
        "# Saving and Loading Models\n",
        "\n",
        "In this tutorial we will learn how we can take a trained model, save it, and then load it back to keep training it or use it to perform inference. In particular, we will use transfer learning to train a classifier to classify images of cats and dogs, just like we did in the previous lesson. We will then take our trained model and save it as an HDF5 file, which is the format used by Keras. We will then load this model, use it to perform predictions, and then continue to train the model. Finally, we will save our trained model as a TensorFlow SavedModel and then we will download it to a local disk, so that it can later be used for deployment in different platforms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slSd1-O1qT8M",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Concepts that will be covered in this Colab\n",
        "\n",
        "1. Saving models in HDF5 format for Keras\n",
        "2. Saving models in the TensorFlow SavedModel format\n",
        "3. Loading models\n",
        "4. Download models to Local Disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2QnhROwqVKr",
        "colab_type": "text"
      },
      "source": [
        "# Imports\n",
        "\n",
        "In this Colab we will use the TensorFlow 2.0 Beta version. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K41XjMv5qKWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  !pip install -U \"tensorflow-gpu==2.0.0rc0\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6HlCKx-qt0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "ddabae7d-6d8a-4344-f205-63b9eb00fda5"
      },
      "source": [
        "!pip install -U tensorflow_hub\n",
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow_hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /tensorflow-2.1.0/python3.6 (from tensorflow_hub) (3.11.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /tensorflow-2.1.0/python3.6 (from tensorflow_hub) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /tensorflow-2.1.0/python3.6 (from tensorflow_hub) (1.13.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /tensorflow-2.1.0/python3.6 (from protobuf>=3.4.0->tensorflow_hub) (45.0.0)\n",
            "Requirement already up-to-date: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (3.11.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (1.13.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (2.22.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /tensorflow-2.1.0/python3.6 (from protobuf>=3.6.1->tensorflow_datasets) (45.0.0)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow_datasets) (1.25.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYKafhAtqvlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml4dOCpkrAHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRGBK8b1rjyM",
        "colab_type": "text"
      },
      "source": [
        "# Part 1: Load the Cats vs. Dogs Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yl8YiVyrkw7",
        "colab_type": "text"
      },
      "source": [
        "We will use TensorFlow Datasets to load the Dogs vs Cats dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saBtnL-urhEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_examples, validation_examples), info = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZbowGZskh9",
        "colab_type": "text"
      },
      "source": [
        "The images in the Dogs vs. Cats dataset are not all the same size. So, we need to reformat all images to the resolution expected by MobileNet (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IempjBAuslCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "    return image, label\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_RES = 224\n",
        "\n",
        "train_batches = train_examples.cache().shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_examples.cache().map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9nMUp43VvL",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Transfer Learning with TensorFlow Hub\n",
        "\n",
        "We will now use TensorFlow Hub to do Transfer Learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4txXv9B13O6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}